import os

import chromadb
from chromadb.utils import embedding_functions
from app.core import config
import logging
from typing import List, Dict, Any, Optional
from chromadb.config import Settings

# Configure basic logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize ChromaDB client
try:
    chroma_settings = Settings()
    if os.getenv("TEST_ENV_ALLOW_CHROMA_RESET") == "true":  # An env var to signal testing
        chroma_settings = Settings(allow_reset=True, anonymized_telemetry=False)
        logger.info("ChromaDB initialized with allow_reset=True for testing.")

    persistent_client = chromadb.PersistentClient(
        path=config.VECTOR_DB_PATH,
        settings=chroma_settings  # Pass settings here
    )
    logger.info(f"ChromaDB persistent client initialized at path: {config.VECTOR_DB_PATH}")

except Exception as e:
    logger.error(f"Failed to initialize ChromaDB client: {e}", exc_info=True)
    persistent_client = None

SENTENCE_TRANSFORMER_MODEL_NAME = 'all-MiniLM-L6-v2'
try:
    logger.info(f"Initializing Sentence Transformer Embedding Function with model: {SENTENCE_TRANSFORMER_MODEL_NAME}")
    # This uses sentence_transformers library under the hood.
    default_embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(
        model_name=SENTENCE_TRANSFORMER_MODEL_NAME
    )
    logger.info("Sentence Transformer Embedding Function initialized successfully.")
except Exception as e:
    logger.error(f"Failed to initialize Sentence Transformer Embedding Function: {e}", exc_info=True)
    logger.error("This likely means the sentence-transformers library is not installed or the model name is incorrect.")
    logger.error("Please ensure 'sentence-transformers' is in your requirements.txt and installed.")
    default_embedding_function = None

# Global collection name for simplicity.
DEFAULT_COLLECTION_NAME = "rag_documents"


def get_or_create_collection(collection_name: str = DEFAULT_COLLECTION_NAME):
    """
    Gets an existing collection or creates a new one if it doesn't exist.
    Uses the pre-configured Sentence Transformer embedding function.
    """
    if not persistent_client:
        logger.error("ChromaDB client is not initialized.")
        return None
    if not default_embedding_function:
        logger.error("Default Embedding Function (Sentence Transformer) is not initialized. Cannot create collection.")
        return None

    try:
        collection = persistent_client.get_or_create_collection(
            name=collection_name,
            embedding_function=default_embedding_function
        )
        logger.info(f"Successfully got or created collection: {collection_name} using Sentence Transformers.")
        return collection
    except Exception as e:
        logger.error(f"Error getting or creating collection {collection_name}: {e}", exc_info=True)
        return None


def add_chunks_to_vector_db(
        doc_id: str,
        chunks: List[str],
        collection_name: str = DEFAULT_COLLECTION_NAME,
        chunk_metadatas: Optional[List[Dict[str, Any]]] = None
) -> bool:
    """
    Adds text chunks and their embeddings to the specified ChromaDB collection.
    Embeddings are generated by ChromaDB using the collection's configured embedding function.

    Args:
        doc_id (str): The unique ID of the document these chunks belong to.
        chunks (List[str]): The list of text chunks.
        collection_name (str): The name of the collection to add to.
        chunk_metadatas (Optional[List[Dict[str, Any]]]): Optional list of metadata for each chunk.

    Returns:
        bool: True if successful, False otherwise.
    """
    collection = get_or_create_collection(collection_name)
    if not collection:
        logger.error(f"Failed to get or create collection '{collection_name}'. Cannot add chunks.")
        return False

    if not chunks:
        logger.info("No chunks provided to add to vector DB.")
        return True

    ids = [f"{doc_id}_chunk_{i}" for i in range(len(chunks))]

    metadatas_to_store = []
    if chunk_metadatas and len(chunk_metadatas) == len(chunks):
        for i, meta in enumerate(chunk_metadatas):
            base_meta = {"doc_id": doc_id, "chunk_index": i}
            base_meta.update(meta)
            metadatas_to_store.append(base_meta)
    else:
        if chunk_metadatas:
            logger.warning("Provided chunk_metadatas length does not match chunks length. Using default metadata.")
        for i in range(len(chunks)):
            metadatas_to_store.append({"doc_id": doc_id, "chunk_index": i})

    try:
        # ChromaDB generates embeddings automatically using the collection's embedding_function
        collection.add(
            documents=chunks,
            metadatas=metadatas_to_store,
            ids=ids
        )
        logger.info(
            f"Successfully added {len(chunks)} chunks for doc_id '{doc_id}' to collection '{collection_name}' using local embeddings.")
        return True
    except Exception as e:
        logger.error(f"Error adding chunks to ChromaDB for doc_id '{doc_id}': {e}", exc_info=True)
        return False


# Example Usage (for testing this module directly)
if __name__ == "__main__":
    if not persistent_client or not default_embedding_function:
        print("ChromaDB client or Sentence Transformer EF not initialized. Exiting test.")
    else:
        test_doc_id = "local_embed_test_doc_001"
        sample_chunks = [
            "This is the first sample chunk from a test document using local embeddings.",
            "Another piece of text, representing the second chunk, embedded locally.",
            "The final example chunk for testing local embedding purposes."
        ]

        print(f"\n--- Test: Adding chunks for doc_id: {test_doc_id} (Local Embeddings) ---")
        success = add_chunks_to_vector_db(doc_id=test_doc_id, chunks=sample_chunks)
        if success:
            print(f"Chunks added successfully for {test_doc_id}.")

            collection = get_or_create_collection()
            if collection:
                print(f"Collection '{DEFAULT_COLLECTION_NAME}' count: {collection.count()}")
                # Querying also uses the collection's configured embedding function
                results = collection.query(
                    query_texts=["example chunk locally"],  # Query text will also be embedded locally
                    n_results=2,
                    include=['metadatas', 'documents', 'distances']
                )
                print("\nQuery results for 'example chunk locally':")
                if results['ids'] and results['ids'][0]:  # Check if results are not empty
                    for i in range(len(results['ids'][0])):
                        print(f"  ID: {results['ids'][0][i]}")
                        print(f"  Distance: {results['distances'][0][i]}")
                        print(f"  Metadata: {results['metadatas'][0][i]}")
                        print(f"  Document: {results['documents'][0][i][:50]}...")
                        print("-" * 20)
                else:
                    print("No results found for the query.")
        else:
            print(f"Failed to add chunks for {test_doc_id}.")
